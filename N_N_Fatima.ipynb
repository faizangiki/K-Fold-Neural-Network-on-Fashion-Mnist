{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras import Sequential\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import History \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_learning_curve(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss']) \n",
    "    plt.title('Validation loss history')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_learning_acc(history):\n",
    "    # Plot history: Accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Validation accuracy history')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 1 with 3 Hidden Layer 10 neuron each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    inp = Input(shape=(28,28))\n",
    "    flate_layer = Flatten()(inp)\n",
    "    hidden_1 = Dense(10)(flate_layer)\n",
    "    hidden_2 = Dense(10)(hidden_1)\n",
    "    hidden_3 = Dense(10)(hidden_2)\n",
    "    final_layer = Dense(10, activation='softmax')(hidden_3)\n",
    "    model = Model(inputs=inp, outputs=final_layer)\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "batch_size = 512\n",
    "no_epochs = 15\n",
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "#train_images,test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "inputs  = np.concatenate((train_images, test_images))\n",
    "target =  np.concatenate((train_labels, test_labels))\n",
    "\n",
    "\n",
    "\n",
    "# train_images=tf.keras.utils.normalize(train_images)\n",
    "# test_images=tf.keras.utils.normalize(test_images)\n",
    "images = inputs/255.0\n",
    "#labels  = target/255.0\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "for train, test in kfold.split(images, target):\n",
    "    # create model\n",
    "    print(len(train))\n",
    "    \n",
    "    model=create_model()    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "     \n",
    "    # Fit data to model\n",
    "    history = model.fit(images[train], target[train],validation_split=0.1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=1)\n",
    "    visualize_learning_curve(history)\n",
    "    visualize_learning_acc(history)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(images[test], target[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    \n",
    "r1 = np.mean(acc_per_fold) \n",
    "print(\"\\nMean Accuracy : \", r1) \n",
    "  \n",
    "r2 = np.std(loss_per_fold) \n",
    "print(\"\\nstandard deviation : \", r2) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 2 with 1 hidden layer with 10 Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model_1():\n",
    "    # create model\n",
    "    inp = Input(shape=(28,28))\n",
    "    flate_layer = Flatten()(inp)\n",
    "    hidden_1 = Dense(10)(flate_layer)\n",
    "    final_layer = Dense(10,activation='softmax')(hidden_1)\n",
    "    model = Model(inputs=inp, outputs=final_layer)\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "batch_size = 512\n",
    "no_epochs = 15\n",
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "#train_images,test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "inputs  = np.concatenate((train_images, test_images))\n",
    "target =  np.concatenate((train_labels, test_labels))\n",
    "\n",
    "\n",
    "\n",
    "# train_images=tf.keras.utils.normalize(train_images)\n",
    "# test_images=tf.keras.utils.normalize(test_images)\n",
    "images = inputs/255.0\n",
    "#labels  = target/255.0\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "for train, test in kfold.split(images, target):\n",
    "    # create model\n",
    "    print(len(train))\n",
    "    \n",
    "    model=create_model_1()    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "     \n",
    "    # Fit data to model\n",
    "    history = model.fit(images[train], target[train],validation_split=0.1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=1)\n",
    "    visualize_learning_curve(history)\n",
    "    visualize_learning_acc(history)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(images[test], target[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    \n",
    "r1 = np.mean(acc_per_fold) \n",
    "print(\"\\nMean Accuracy : \", r1) \n",
    "  \n",
    "r2 = np.std(loss_per_fold) \n",
    "print(\"\\nstandard deviation : \", r2) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 1 with sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model_2():\n",
    "    # create model\n",
    "    inp = Input(shape=(28,28))\n",
    "    flate_layer = Flatten()(inp)\n",
    "    hidden_1 = Dense(10,activation='sigmoid')(flate_layer)\n",
    "    hidden_2 = Dense(10,activation='sigmoid')(hidden_1)\n",
    "    hidden_3 = Dense(10,activation='sigmoid')(hidden_2)\n",
    "    final_layer = Dense(10, activation='softmax')(hidden_3)\n",
    "    model = Model(inputs=inp, outputs=final_layer)\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "batch_size = 512\n",
    "no_epochs = 15\n",
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "#train_images,test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "inputs  = np.concatenate((train_images, test_images))\n",
    "target =  np.concatenate((train_labels, test_labels))\n",
    "\n",
    "\n",
    "\n",
    "# train_images=tf.keras.utils.normalize(train_images)\n",
    "# test_images=tf.keras.utils.normalize(test_images)\n",
    "images = inputs/255.0\n",
    "#labels  = target/255.0\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "for train, test in kfold.split(images, target):\n",
    "    # create model\n",
    "    print(len(train))\n",
    "    \n",
    "    model=create_model_2()    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "     \n",
    "    # Fit data to model\n",
    "    history = model.fit(images[train], target[train],validation_split=0.1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=1)\n",
    "    visualize_learning_curve(history)\n",
    "    visualize_learning_acc(history)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(images[test], target[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    \n",
    "r1 = np.mean(acc_per_fold) \n",
    "print(\"\\nMean Accuracy : \", r1) \n",
    "  \n",
    "r2 = np.std(loss_per_fold) \n",
    "print(\"\\nstandard deviation : \", r2) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 1 with sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model_3():\n",
    "    # create model\n",
    "    inp = Input(shape=(28,28))\n",
    "    flate_layer = Flatten()(inp)\n",
    "    hidden_1 = Dense(10,activation='tanh')(flate_layer)\n",
    "    hidden_2 = Dense(10,activation='tanh')(hidden_1)\n",
    "    hidden_3 = Dense(10,activation='tanh')(hidden_2)\n",
    "    final_layer = Dense(10, activation='softmax')(hidden_3)\n",
    "    model = Model(inputs=inp, outputs=final_layer)\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "batch_size = 512\n",
    "no_epochs = 15\n",
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "#train_images,test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "inputs  = np.concatenate((train_images, test_images))\n",
    "target =  np.concatenate((train_labels, test_labels))\n",
    "\n",
    "\n",
    "\n",
    "# train_images=tf.keras.utils.normalize(train_images)\n",
    "# test_images=tf.keras.utils.normalize(test_images)\n",
    "images = inputs/255.0\n",
    "#labels  = target/255.0\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "model_save = \n",
    "for train, test in kfold.split(images, target):\n",
    "    # create model\n",
    "    print(len(train))\n",
    "    \n",
    "    model=create_model_3()    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "     \n",
    "    # Fit data to model\n",
    "    history = model.fit(images[train], target[train],validation_split=0.1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=1)\n",
    "    visualize_learning_curve(history)\n",
    "    visualize_learning_acc(history)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(images[test], target[test], verbose=0)\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    \n",
    "r1 = np.mean(acc_per_fold) \n",
    "print(\"\\nMean Accuracy : \", r1) \n",
    "  \n",
    "r2 = np.std(loss_per_fold) \n",
    "print(\"\\nstandard deviation : \", r2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 1 with Relu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model_4():\n",
    "    # create model\n",
    "    inp = Input(shape=(28,28))\n",
    "    flate_layer = Flatten()(inp)\n",
    "    hidden_1 = Dense(10,activation='relu')(flate_layer)\n",
    "    hidden_2 = Dense(10,activation='relu')(hidden_1)\n",
    "    hidden_3 = Dense(10,activation='relu')(hidden_2)\n",
    "    final_layer = Dense(10, activation='softmax')(hidden_3)\n",
    "    model = Model(inputs=inp, outputs=final_layer)\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "batch_size = 512\n",
    "no_epochs = 15\n",
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "#train_images,test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "inputs  = np.concatenate((train_images, test_images))\n",
    "target =  np.concatenate((train_labels, test_labels))\n",
    "\n",
    "\n",
    "\n",
    "# train_images=tf.keras.utils.normalize(train_images)\n",
    "# test_images=tf.keras.utils.normalize(test_images)\n",
    "images = inputs/255.0\n",
    "#labels  = target/255.0\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "for train, test in kfold.split(images, target):\n",
    "    # create model\n",
    "    print(len(train))\n",
    "    \n",
    "    model=create_model_4()    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "     \n",
    "    # Fit data to model\n",
    "    history = model.fit(images[train], target[train],validation_split=0.1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=1)\n",
    "    visualize_learning_curve(history)\n",
    "    visualize_learning_acc(history)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(images[test], target[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    \n",
    "r1 = np.mean(acc_per_fold) \n",
    "print(\"\\nMean Accuracy : \", r1) \n",
    "  \n",
    "r2 = np.std(loss_per_fold) \n",
    "print(\"\\nstandard deviation : \", r2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In all the networks, network with relu activation function perform better then all other networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
